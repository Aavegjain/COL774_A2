{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes():\n",
    "    def __init__(self, df, no_of_labels, col_name = \"CoronaTweet\"):\n",
    "        self.df = df \n",
    "        self.no_of_labels = no_of_labels\n",
    "        self.probabilities = dict()\n",
    "        self.y_prob = [0 for i in range(self.no_of_labels)]\n",
    "        self.log_probabilities, self.y_log_prob, self.set_of_words = dict(), [0 for i in range(self.no_of_labels)] , set()\n",
    "        self.sets = [set() for i in range(self.no_of_labels)] \n",
    "        self.frequencies = dict() \n",
    "        self.SIZE = 0 \n",
    "        self.SIZES = [0 for i in range(self.no_of_labels)]\n",
    "        self.col_name = col_name\n",
    "        self.removed = 0 \n",
    "    \n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = text.split(\" \")\n",
    "        text = [word.lower() for word in text]  \n",
    "        return text\n",
    "\n",
    "    def convert_to_feature(self):\n",
    "        self.df[\"splitWords\"] = (self.df[self.col_name]).apply(self.preprocess)\n",
    "\n",
    "    def compute_freqs(self):\n",
    "        self.SIZES = [0 for i in range(self.no_of_labels)] \n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            if (row[\"Sentiment\"] == \"Positive\"):\n",
    "                row[\"Sentiment\"] = 2\n",
    "            elif (row[\"Sentiment\"] == \"Neutral\"):\n",
    "                row[\"Sentiment\"] = 1\n",
    "            else:\n",
    "                row[\"Sentiment\"] = 0\n",
    "            i = row[\"Sentiment\"] # i is class \n",
    "            for word in row[\"splitWords\"]:\n",
    "                    # if (word == \"\")  : continue\n",
    "                    self.SIZES[i] += 1\n",
    "                    if (word in self.set_of_words):\n",
    "                        self.frequencies[word][i] += 1\n",
    "                    else:\n",
    "                        self.set_of_words.add(word)\n",
    "                        self.frequencies[word] = [0 for j in range(self.no_of_labels)] \n",
    "                        self.frequencies[word][i] += 1\n",
    "                        # print(self.frequencies[word])\n",
    "                    self.sets[i].add(word)\n",
    "\n",
    "        self.SIZE = len(self.set_of_words) \n",
    "    \n",
    "    def compute_log_probs(self):\n",
    "\n",
    "        for word in self.set_of_words:\n",
    "            self.probabilities[word] = [0 for i in range(self.no_of_labels)]\n",
    "            self.log_probabilities[word] = [0 for i in range(self.no_of_labels)]\n",
    "            for i in range(self.no_of_labels):\n",
    "                self.probabilities[word][i] = (self.frequencies[word][i] + 1) / (self.SIZES[i] + self.SIZE)\n",
    "                # self.probabilities[word][i] = (self.frequencies[word][i] + 1) / (self.SIZES[i] + len(self.sets[i])) \n",
    "                self.log_probabilities[word][i] = math.log(self.probabilities[word][i])\n",
    "        \n",
    "        total_size = sum(self.SIZES)\n",
    "\n",
    "        self.y_prob = [self.SIZES[i]/total_size for i in range(self.no_of_labels)]\n",
    "        self.y_log_prob = [math.log(self.y_prob[i]) for i in range(self.no_of_labels)]\n",
    "    \n",
    "    def compute_canonical_log_prob(self, text, label): # ignores P(x) in P(y | x) = P(x|y) * P(y)/ P(x) \n",
    "        word_list = self.preprocess(text)\n",
    "        log_prob = 0 \n",
    "        for word in word_list:\n",
    "            # if (word == \"\") : continue # ignore empty strings \n",
    "            if (word in self.set_of_words):\n",
    "                log_prob += self.log_probabilities[word][label] \n",
    "            else:\n",
    "                # log_prob -= math.log((SIZES[label] + SIZE))  # prob is 1 / (SIZES[label] + self.SIZE)\n",
    "                continue \n",
    "        log_prob += self.y_log_prob[label] \n",
    "        return log_prob  \n",
    "    \n",
    "    def train(self):\n",
    "        self.convert_to_feature() \n",
    "        self.compute_freqs()\n",
    "        self.compute_log_probs() \n",
    "        print(\"training complete\") \n",
    "\n",
    "    def predictor(self, text):\n",
    "       \n",
    "        log_probs = [self.compute_canonical_log_prob(text, i) for i in range(self.no_of_labels)] \n",
    "        max_prob = log_probs[0] \n",
    "        max_label = 0 \n",
    "\n",
    "        for i in range(self.no_of_labels):\n",
    "            if (log_probs[i] >= max_prob):\n",
    "                max_prob = log_probs[i]\n",
    "                max_label = i\n",
    "            # elif (log_probs[i] == max_prob):\n",
    "            #     max_label = max_label if (self.SIZES[max_label] > self.SIZES[i])  else i \n",
    "        return max_label\n",
    "    \n",
    "    \n",
    "\n",
    "    def compute_accuracy(self, df ): # input is a dataframe\n",
    "        correct = 0 \n",
    "        for idx,rows in df.iterrows():\n",
    "            prediction = self.predictor(rows[self.col_name]) \n",
    "            # print(f\"{prediction} {rows['Sentiment']}\")\n",
    "            rows[\"Sentiment\"] = 0 if (rows[\"Sentiment\"] == \"Negative\") else 2 if (rows[\"Sentiment\"] == \"Positive\") else 1\n",
    "            if (prediction == rows[\"Sentiment\"]):\n",
    "                correct += 1\n",
    "        return correct / len(df) \n",
    "\n",
    "    def compute_confusion_matrix(self, df):\n",
    "        confusion_matrix = np.zeros((self.no_of_labels, self.no_of_labels)) \n",
    "        for idx,rows in df.iterrows():\n",
    "            prediction = self.predictor(rows[self.col_name]) \n",
    "            # print(f\"{prediction} {rows['Sentiment']}\")\n",
    "            rows[\"Sentiment\"] = 0 if (rows[\"Sentiment\"] == \"Negative\") else 2 if (rows[\"Sentiment\"] == \"Positive\") else 1\n",
    "            confusion_matrix[rows[\"Sentiment\"]][prediction] += 1 \n",
    "           \n",
    "        return confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('../data/Corona_train.csv') \n",
    "print(df) \n",
    "no_of_labels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_classifier = Naive_Bayes(df, 3) \n",
    "weak_classifier.train() \n",
    "training_accuracy = weak_classifier.compute_accuracy(df)\n",
    "print(training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/Corona_validation.csv') \n",
    "test_accuracy = weak_classifier.compute_accuracy(df_test)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising with a word cloud\n",
    "from wordcloud import  WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS) \n",
    "# print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wordcloud(name, database, max_words = 1000000):\n",
    "    wc = WordCloud(background_color=\"white\", max_words = max_words, stopwords=stopwords) \n",
    "    wc.generate(database) \n",
    "\n",
    "    wc.to_file(f\"{name}.png\")\n",
    "\n",
    "    fig = plt.figure() \n",
    "    fig.set_figheight(18) \n",
    "    fig.set_figwidth(14) \n",
    "    \n",
    "    plt.imshow(wc, interpolation='bilinear') \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(no_of_labels):\n",
    "    get_wordcloud(f\"wordcloud_1_{i}\", \" \".join(weak_classifier.sets[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_predictor(text, no_of_labels):\n",
    "    x = np.random.randint(0,no_of_labels) \n",
    "    # assert(x >= 0 and x < 3)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def always_positive_predictor(text, no_of_labels): \n",
    "    return no_of_labels - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_random_predictor_accuracy(df, no_of_labels, confusion_matrix):\n",
    "    correct  = 0 \n",
    "    for idx,rows in df.iterrows():\n",
    "        prediction = random_predictor(rows[\"CoronaTweet\"], no_of_labels) \n",
    "        rows[\"Sentiment\"] = 0 if (rows[\"Sentiment\"] == \"Negative\") else 2 if (rows[\"Sentiment\"] == \"Positive\") else 1\n",
    "        confusion_matrix[rows[\"Sentiment\"]][prediction] += 1 \n",
    "        if (prediction == rows[\"Sentiment\"]):\n",
    "            correct += 1\n",
    "    return correct / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_allpositive_predictor_accuracy(df, no_of_labels, confusion_matrix):\n",
    "    correct  = 0 \n",
    "    for idx,rows in df.iterrows():\n",
    "        prediction = always_positive_predictor(rows[\"CoronaTweet\"], no_of_labels) \n",
    "        rows[\"Sentiment\"] = 0 if (rows[\"Sentiment\"] == \"Negative\") else 2 if (rows[\"Sentiment\"] == \"Positive\") else 1\n",
    "        confusion_matrix[rows[\"Sentiment\"]][prediction] += 1 \n",
    "        if (prediction == rows[\"Sentiment\"]):\n",
    "            correct += 1\n",
    "    return correct / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_confusion_matrix( confusion_matrix, name):\n",
    "        correct = 0 \n",
    "        total = 0 \n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.3) \n",
    "        max_diag = 0 \n",
    "        max_diag_label = 0\n",
    "        for i in range(confusion_matrix.shape[0]):\n",
    "            for j in range(confusion_matrix.shape[1]):\n",
    "                total += confusion_matrix[i,j]\n",
    "                if (i == j) : \n",
    "                    correct += confusion_matrix[i,j]\n",
    "                    if (max_diag < confusion_matrix[i,j]):\n",
    "                        max_diag = confusion_matrix[i,j]\n",
    "                        max_diag_label = i\n",
    "    \n",
    "                ax.text(x=j, y=i,s= confusion_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "        \n",
    "        plt.xlabel('Predictions', fontsize=18)\n",
    "        plt.ylabel('Actuals', fontsize=18)\n",
    "        plt.title('Confusion Matrix', fontsize=18)\n",
    "        plt.savefig(f\"confusion_matrix_{name}.png\")\n",
    "        # plt.show()\n",
    "        print(f\"accuracy is {correct/total}\")\n",
    "        print(f\"label with max diagonal is {max_diag_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = weak_classifier.compute_confusion_matrix(df)\n",
    "m2 = weak_classifier.compute_confusion_matrix(df_test) \n",
    "\n",
    "draw_confusion_matrix(m1, \"og_train\")\n",
    "draw_confusion_matrix(m2, \"og_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_cm = np.array([ [0 for i in range(no_of_labels)] for j in range(no_of_labels)])\n",
    "random_accuracy = compute_random_predictor_accuracy(df_test, no_of_labels, random_cm)\n",
    "draw_confusion_matrix(random_cm, \"random_test\") \n",
    "\n",
    "allpositive_cm = np.array([ [0 for i in range(no_of_labels)] for j in range(no_of_labels)])\n",
    "allpositive_accuracy = compute_allpositive_predictor_accuracy(df_test, no_of_labels, allpositive_cm)\n",
    "draw_confusion_matrix(allpositive_cm, \"allpositive_test\" )\n",
    "\n",
    "random_cm = np.array([ [0 for i in range(no_of_labels)] for j in range(no_of_labels)])\n",
    "compute_random_predictor_accuracy(df, no_of_labels, random_cm)\n",
    "draw_confusion_matrix(random_cm, \"random_training\") \n",
    "\n",
    "allpositive_cm = np.array([ [0 for i in range(no_of_labels)] for j in range(no_of_labels)])\n",
    "compute_allpositive_predictor_accuracy(df, no_of_labels, allpositive_cm)\n",
    "draw_confusion_matrix(allpositive_cm, \"allpositive_training\" )\n",
    "\n",
    "print(random_accuracy) \n",
    "print(allpositive_accuracy)\n",
    "print(f\"improvement over random baseline is {test_accuracy - random_accuracy}\")\n",
    "print(f\"improvement over all positive baseline is {test_accuracy - allpositive_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all cases, class 2 or \"Positive\" has the highest value of diagonal entry \n",
    "This means that the maximum number of correct predictions have been made for \"Positive\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming, lematizing and removing stop words\n",
    "import nltk\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet') \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english')) \n",
    "print(stopwords)\n",
    "# new_stop_words = [WordNetLemmatizer().lemmatize(word) for word in stopwords]\n",
    "# print(new_stop_words)\n",
    "# print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes_2(Naive_Bayes):\n",
    "    def preprocess(self, text):\n",
    "      \n",
    "        text = re.sub(r'http\\S*', '', text, flags=re.MULTILINE)\n",
    "        text = text.replace(\"Ã‚\", \"\") \n",
    "        text = text.replace(\"\\x92\", \"\")\n",
    "        text = text.replace(\"\\x93\", \"\")\n",
    "        text = text.replace(\"\\x94\", \"\")\n",
    "        \n",
    "        # text = re.sub(r'Ã¢[0-9][0-9]', '', text, flags=re.MULTILINE)\n",
    "        wordlist = word_tokenize(text.lower())\n",
    "        wordlist = [WordNetLemmatizer().lemmatize(word) for word in wordlist]\n",
    "        wordlist = [word for word in wordlist if word not in stopwords and word not in punctuation]\n",
    "        \n",
    "       \n",
    "        return wordlist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_classifier = Naive_Bayes_2(df, 3) \n",
    "strong_classifier.train()\n",
    "strong_training_accuracy = strong_classifier.compute_accuracy(df) \n",
    "print(strong_training_accuracy) \n",
    "strong_test_accuracy = strong_classifier.compute_accuracy(df_test) \n",
    "print(strong_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = \" \".join(strong_classifier.sets[0])\n",
    "d2 = \" \".join(weak_classifier.sets[0])\n",
    "\n",
    "get_wordcloud( \"wordcloud_2_0\", \" \".join(strong_classifier.sets[0]) ) \n",
    "get_wordcloud( \"wordcloud_2_1\", \" \".join(strong_classifier.sets[1]) )\n",
    "get_wordcloud( \"wordcloud_2_2\", \" \".join(strong_classifier.sets[2]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments : validation accuracy doesn't increase much, going from 65.05 to 66.50 percent. Thus lematization and stop word removal doesnt improve accuracy much.  This could mean that the dataset does not exhibit strong dependence on inflectional forms of lemmas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ngrams(Naive_Bayes):\n",
    "    def __init__(self, df , no_of_labels, n, col_name = \"CoronaTweet\"):\n",
    "        self.df = df \n",
    "        self.no_of_labels = no_of_labels\n",
    "        self.frequencies = dict() \n",
    "        self.probabilities, self.log_probabilities  = dict(), dict()\n",
    "        self.gram_size = n \n",
    "        self.SIZE = [0] * n  \n",
    "        self.SIZES = [[0] * no_of_labels] * n  \n",
    "        self.sets =  [ [set()] * no_of_labels ] * n  \n",
    "        self.set_of_words = [set()] * n \n",
    "        self.y_prob, self.y_log_prob = [0] * self.no_of_labels, [0] * self.no_of_labels\n",
    "        self.col_name = col_name \n",
    "        \n",
    "    \n",
    "    def get_grams(self, n, text):\n",
    "        # returns the ngrams of the text\n",
    "        wordlist = text.split(\" \")\n",
    "        ngrams = [] \n",
    "        size = len(wordlist) \n",
    "        for i in range(size- n + 1):\n",
    "            gram = tuple() \n",
    "            for j in range(n):\n",
    "                gram += (wordlist[i+j],) \n",
    "            ngrams.append(gram)\n",
    "        return ngrams\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        text = re.sub(r'http\\S*', '', text, flags=re.MULTILINE)\n",
    "        text = text.replace(\"Ã‚\", \"\") \n",
    "        text = text.replace(\"\\x92\", \"\")\n",
    "        text = text.replace(\"\\x93\", \"\")\n",
    "        text = text.replace(\"\\x94\", \"\")\n",
    "        # text = re.sub(r'Ã¢[0-9][0-9]', '', text, flags=re.MULTILINE)\n",
    "        wordlist = word_tokenize(text.lower())\n",
    "        wordlist = [WordNetLemmatizer().lemmatize(word) for word in wordlist]\n",
    "        wordlist = [word for word in wordlist if word not in stopwords and word not in punctuation]\n",
    "    \n",
    "\n",
    "        new_text = \" \".join(wordlist) \n",
    "        ans = [] \n",
    "        for i in range(1, self.gram_size + 1):\n",
    "            ans.extend(self.get_grams(i, new_text)) \n",
    "        return ans\n",
    "\n",
    "    def compute_freqs(self):\n",
    "        for idx, row in self.df.iterrows():\n",
    "            if (row[\"Sentiment\"] == \"Positive\"):\n",
    "                row[\"Sentiment\"] = 2\n",
    "            elif (row[\"Sentiment\"] == \"Neutral\"):\n",
    "                row[\"Sentiment\"] = 1\n",
    "            else:\n",
    "                row[\"Sentiment\"] = 0\n",
    "            i = row[\"Sentiment\"]\n",
    "\n",
    "            for gram in row[\"splitWords\"]:\n",
    "                gram_size = len(gram) \n",
    "                # print(f\"len of {gram} is {gram_size}\")\n",
    "                self.SIZES[gram_size - 1][i] += 1\n",
    "                if (gram in self.set_of_words[gram_size - 1]):\n",
    "                    self.frequencies[gram][i] += 1\n",
    "                else:\n",
    "                    self.set_of_words[gram_size - 1].add(gram)\n",
    "                    self.frequencies[gram] = [0 for j in range(self.no_of_labels)] \n",
    "                    self.frequencies[gram][i] += 1\n",
    "                self.sets[gram_size - 1][i].add(gram)\n",
    "\n",
    "        self.SIZE = [ len(self.set_of_words[i]) for i in range(self.gram_size) ]   \n",
    "    \n",
    "    def compute_log_probs(self):\n",
    "        for i in range(self.gram_size):\n",
    "            for word in self.set_of_words[i]:\n",
    "                self.probabilities[word] = [0 for k in range(self.no_of_labels)]\n",
    "                self.log_probabilities[word] = [ 0 for k in range(self.no_of_labels)]\n",
    "                for j in range(self.no_of_labels):\n",
    "                    self.probabilities[word][j] = (self.frequencies[word][j] + 1) / (self.SIZES[i][j] + self.SIZE[i])\n",
    "                    self.log_probabilities[word][j] = math.log(self.probabilities[word][j])\n",
    "        \n",
    "        total_class_sizes = [ 0 for w in range(self.no_of_labels)]\n",
    "        \n",
    "        for i in range(self.gram_size):\n",
    "            for j in range(self.no_of_labels):\n",
    "                total_class_sizes[j] += self.SIZES[i][j]\n",
    "\n",
    "        total_size = sum(total_class_sizes) \n",
    "        self.y_prob = [total_class_sizes[i]/total_size for i in range(self.no_of_labels)]\n",
    "        self.y_log_prob = [math.log(self.y_prob[i]) for i in range(self.no_of_labels)] \n",
    "    \n",
    "    def compute_canonical_log_prob(self, text, label): # ignores P(x) in P(y | x) = P(x|y) * P(y)/ P(x) \n",
    "        word_list = self.preprocess(text)\n",
    "        log_prob = 0 \n",
    "        for word in word_list:\n",
    "            # if (word == \"\") : continue # ignore empty strings \n",
    "            size = len(word)\n",
    "            if (word in self.set_of_words[size - 1]):\n",
    "                log_prob += self.log_probabilities[word][label] \n",
    "            else:\n",
    "                # log_prob -= math.log((SIZES[label] + SIZE))  # prob is 1 / (SIZES[label] + SIZE)\n",
    "                continue \n",
    "        log_prob += self.y_log_prob[label] \n",
    "        return log_prob\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_classifier = Ngrams(df, 3, 2)\n",
    "ngrams_classifier.train()\n",
    "training_accuracy = ngrams_classifier.compute_accuracy(df)\n",
    "test_accuracy = ngrams_classifier.compute_accuracy(df_test)\n",
    "print(training_accuracy)\n",
    "print(test_accuracy)\n",
    "# text = \"Learning ML and AI is fun\"\n",
    "# print(ngrams_classifier.get_grams(3, text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %pip install emoji \n",
    "# import emoji \n",
    "\n",
    "# def extract_emojis(s):\n",
    "#   emojis_dict = emoji.emoji_list(s)\n",
    "#   emojis = [] \n",
    "#   for dict in emojis_dict:\n",
    "#       emojis.append(dict[\"emoji\"]) \n",
    "#   return emojis \n",
    "\n",
    "# positive_emojis = [\"ðŸ˜€\", \"ðŸ˜Š\", \"ðŸ˜„\", \"ðŸ˜\", \"ðŸ˜\", \"ðŸ‘\", \"ðŸŒŸ\", \"ðŸ’–\", \"ðŸŽ‰\", \"ðŸ˜ƒ\"] \n",
    "# negative_emojis = [\"ðŸ˜ž\", \"ðŸ˜¢\", \"ðŸ˜ \", \"ðŸ˜’\", \"ðŸ˜”\", \"ðŸ’”\", \"ðŸ™\", \"ðŸ˜‘\", \"ðŸ˜•\", \"ðŸ˜£\"]         \n",
    "# emoji_weight = 5          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and read a file \n",
    "\n",
    "f = open(\"./AFINN-en-165.txt\", \"r\") \n",
    "text = f.read() \n",
    "text = text.split(\"\\n\") \n",
    "positive_words = []\n",
    "negative_words = []\n",
    "neutral_words = []\n",
    "for el in text:\n",
    "    \n",
    "    el = el.split()\n",
    "    # print(int(el[-1]))\n",
    "    if (len(el) < 2) : break \n",
    "    if (int(el[-1]) <= -3): negative_words.append(el[0]) \n",
    "    elif (int(el[-1]) >= 3): positive_words.append(el[0])\n",
    "    else: neutral_words.append(el[0])\n",
    "f.close() \n",
    "\n",
    "positive_words = [WordNetLemmatizer().lemmatize(word) for word in positive_words]\n",
    "negative_words = [WordNetLemmatizer().lemmatize(word) for word in negative_words]\n",
    "neutral_words = [WordNetLemmatizer().lemmatize(word) for word in neutral_words]\n",
    "\n",
    "positive_words = set(positive_words)\n",
    "negative_words = set(negative_words)\n",
    "neutral_words = set(neutral_words)\n",
    "\n",
    "print(positive_words)\n",
    "print(negative_words)\n",
    "print(neutral_words)\n",
    "sentiment_word_weight = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Classifier(Naive_Bayes_2):\n",
    "    def preprocess(self, text):\n",
    "        self.sentiment_words = 0 \n",
    "        # print(emojis) \n",
    "        og_text = super().preprocess(text)\n",
    "        # emojis = extract_emojis(og_text) \n",
    "        \n",
    "        # for i in range(emoji_weight):\n",
    "        #     og_text.extend(emojis)\n",
    "        new_list = [] \n",
    "        for word in og_text:\n",
    "            if (word in positive_words or word in negative_words):\n",
    "                self.sentiment_words += 1\n",
    "                temp = [word] * sentiment_word_weight\n",
    "                new_list.extend(temp)\n",
    "        og_text.extend(new_list)\n",
    "        return og_text \n",
    "\n",
    "    def compute_canonical_log_prob(self, text, label): # ignores P(x) in P(y | x) = P(x|y) * P(y)/ P(x) \n",
    "        word_list = self.preprocess(text)\n",
    "        log_prob = 0 \n",
    "        for word in word_list:\n",
    "            # if (word == \"\") : continue # ignore empty strings \n",
    "            if (word in self.set_of_words):\n",
    "                log_prob += self.log_probabilities[word][label] \n",
    "            else:\n",
    "                log_prob -= math.log((self.SIZES[label] + self.SIZE))  # prob is 1 / (SIZES[label] + self.SIZE)\n",
    "                # continue \n",
    "        log_prob += self.y_log_prob[label] \n",
    "        return log_prob  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified = My_Classifier(df, 3)\n",
    "modified.train()\n",
    "training_accuracy = modified.compute_accuracy(df)\n",
    "test_accuracy = modified.compute_accuracy(df_test)\n",
    "print(training_accuracy)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for part e ii), iii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adaptation_1(source_df , target_train_df, target_test_df):\n",
    "    # create an empty df \n",
    "    new_df = pd.DataFrame(columns = [\"ID\", \"Tweet\", \"Sentiment\"]) \n",
    "    for idx, row in source_df.iterrows():\n",
    "        # use pd.concat to add a single row to the dataframe\n",
    "\n",
    "\n",
    "        new_row = pd.DataFrame([{\"ID\" : row[\"ID\"], \"Tweet\": row[\"CoronaTweet\"], \"Sentiment\": row[\"Sentiment\"]}])   \n",
    "        new_df = pd.concat([new_df, new_row], ignore_index = True) \n",
    "        \n",
    "    new_df = pd.concat([new_df, target_train_df], ignore_index = True) \n",
    "    # print(new_df) \n",
    "    classifier = Naive_Bayes_2(new_df, 3, \"Tweet\") \n",
    "    classifier.train()\n",
    "    return classifier.compute_accuracy(target_test_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_adaptation_2(target_train_df, target_test_df):\n",
    "    \n",
    "    source_df = pd.DataFrame(columns=['ID', 'Sentiment', 'Tweet'])\n",
    "    return domain_adaptation_1(source_df, target_train_df, target_test_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [1,2,5,10,25,50,100] \n",
    "target_dfs = [] \n",
    "for i in splits:\n",
    "    target_dfs.append(pd.read_csv(f'../data/Domain_Adaptation/Twitter_train_{i}.csv')) \n",
    "\n",
    "target_test_df = pd.read_csv('../data/Domain_Adaptation/Twitter_validation.csv')  \n",
    "\n",
    "accuracies_1, accuracies_2 = [], [] \n",
    "\n",
    "for target_train_df in target_dfs:\n",
    "    accuracies_1.append(domain_adaptation_1(df, target_train_df, target_test_df))\n",
    "    accuracies_2.append(domain_adaptation_2(target_train_df, target_test_df)) \n",
    "\n",
    "print(accuracies_1)\n",
    "print(accuracies_2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(x, y, xlabel, ylabel, title):\n",
    "    plt.plot(x, y, marker='o', label = title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    # plt.title(title)\n",
    "    # plt.savefig(f\"{name}.png\")\n",
    "    # plt.show()\n",
    "\n",
    "plot_line(splits, accuracies_1, \"% of target training dataset\", \"accuracy\", \"alg1\") \n",
    "plot_line(splits, accuracies_2, \"% of target training dataset\", \"accuracy\", \"alg2\") \n",
    "plt.legend()\n",
    "plt.title(\"accuracy vs % of target training dataset for alg 1,2\") \n",
    "plt.savefig(\"domain_adaptation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that in general when we increase percentage of training data used from target domain, the validation accuracy on the target domain also increases. \n",
    "\n",
    "We also observe that in almost all cases, domain adaptation gives better accuracy than learning from scratch. The percentage of training data from target domain represents how much data is available from target domain. Thus we observe that in almost all cases, using source domain training data makes up for insufficient target domain training data, and provides better accuracy than learning from scratch by leveraging the similarity between source and target domains.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
