{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0X6CKQciM_e",
        "outputId": "77acd6fd-a929-4de8-9002-1f419b5d6647"
      },
      "outputs": [],
      "source": [
        "%pip install cvxopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJR7KaYWlsnd"
      },
      "outputs": [],
      "source": [
        "import cvxopt \n",
        "from cvxopt import matrix\n",
        "from cvxopt import solvers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x2tavLeE0OW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7BtNLzXvB5b",
        "outputId": "57578935-63b4-4d6f-d217-2cfaa7cd4093"
      },
      "outputs": [],
      "source": [
        "# !unzip \"./svm/drive/MyDrive/svm.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr3G9d32w2lk"
      },
      "outputs": [],
      "source": [
        "# %pip install opencv-python\n",
        "import cv2 as cv2 \n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTo2oLz-1A_4"
      },
      "outputs": [],
      "source": [
        "def resize(img_name, new_size):\n",
        "  img = cv2.imread(img_name)\n",
        "  img = img.astype(np.float32)\n",
        "  img = cv2.resize(img,  new_size)\n",
        "  norm_img = img/255.0\n",
        "  norm_img = norm_img.flatten()\n",
        "\n",
        "  return norm_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfLZfmFQ3vWb"
      },
      "outputs": [],
      "source": [
        "# design matrix\n",
        "folder_name = \"./svm/train/3\"\n",
        "\n",
        "X = tuple()\n",
        "new_shape = (16, 16)\n",
        "cnt = 2\n",
        "\n",
        "for filename in os.listdir(folder_name):\n",
        "      file = os.path.join(folder_name, filename)\n",
        "      Y = resize(file, new_shape)\n",
        "      X = X + ( Y[None , ...], )\n",
        "\n",
        "\n",
        "folder_name = \"./svm/train/4\"\n",
        "for filename in os.listdir(folder_name):\n",
        "      file = os.path.join(folder_name, filename)\n",
        "      Y = resize(file, new_shape)\n",
        "      X = X + ( Y[None , ...], )\n",
        "\n",
        "X = np.vstack(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJL0hrc98tj_"
      },
      "outputs": [],
      "source": [
        "# labels\n",
        "Y = np.array([], dtype = int)\n",
        "for i in range( int(X.shape[0]/2) ):\n",
        "  Y = np.append(Y, -1)\n",
        "for i in range(int(X.shape[0]/2)):\n",
        "  Y = np.append(Y, 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJya1_LRBWal"
      },
      "outputs": [],
      "source": [
        "# modelling the problem as a cvx opt problem\n",
        "\n",
        "class SVM:\n",
        "  def __init__(self, X, Y, C):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.C = C\n",
        "    self.m = Y.shape[0]\n",
        "    # print(\"here\")\n",
        "    # self.P = matrix(self.get_P()) for general kernel case \n",
        "    self.linear_kernel_matrix()\n",
        "    self.P = matrix(self.kernel_matrix) \n",
        "    self.q = matrix(np.full( (self.m, ), -1 ))\n",
        "\n",
        "    temp = np.full( (self.m, ) , 1)\n",
        "    temp2 = np.full( (self.m, ) , -1)\n",
        "    self.G = matrix(np.vstack( ( np.diag(temp2), np.diag(temp))  ) )\n",
        "\n",
        "    temp = np.full( (self.m, ), C)\n",
        "    self.h = matrix(np.hstack( ( np.zeros( (self.m, ) ), temp) ) )\n",
        "\n",
        "    self.A = matrix(np.vstack( (self.Y, )))\n",
        "    self.b = matrix(np.zeros( (1,) ))\n",
        "\n",
        "    self.P = matrix( np.array(self.P), tc='d')\n",
        "    self.q = matrix( np.array(self.q), tc='d')\n",
        "    self.G = matrix( np.array(self.G), tc='d')\n",
        "    self.h = matrix( np.array(self.h), tc='d')\n",
        "    self.A = matrix( np.array(self.A), tc='d')\n",
        "    self.b = matrix( np.array(self.b), tc='d')\n",
        "    self.no_of_classes = 2\n",
        "\n",
        "    self.soln = None\n",
        "\n",
        "\n",
        "  def kernel(self, x, y):\n",
        "    return (x.T) @ y # override for different kernels\n",
        "\n",
        "\n",
        "  def gaussian_kernel_matrix(self): # custom function for gaussian kernel\n",
        "    \n",
        "    pairwise_sq_dists = np.sum(self.X**2 , axis=1, keepdims=True) - 2 * np.dot(self.X, self.X.T) + np.sum(self.X**2, axis=1, keepdims=True).T\n",
        "    self.kernel_matrix = np.exp(- self.gamma * pairwise_sq_dists)\n",
        "    # print(np.outer(self.Y, self.Y).shape) \n",
        "    self.kernel_matrix = np.outer(self.Y, self.Y) * self.kernel_matrix\n",
        "    return \n",
        "  \n",
        "  def linear_kernel_matrix(self): # custom function for linear kernel \n",
        "    temp = np.outer(self.Y, self.Y) \n",
        "    self.kernel_matrix = temp * (self.X @ self.X.T) \n",
        "\n",
        "  def get_P(self):\n",
        "    new_shape = (self.m , self.m)\n",
        "    temp = np.zeros(new_shape)\n",
        "    for i in range(self.m):\n",
        "      for j in range(self.m):\n",
        "        temp[i, j] = self.Y[i] * self.Y[j] * self.kernel(self.X[i, :], self.X[j, :])\n",
        "    return temp\n",
        "\n",
        "  def solve(self):\n",
        "    self.soln = solvers.qp(self.P, self.q, self.G, self.h, self.A, self.b)\n",
        "    return self.soln\n",
        "\n",
        "  def get_support_vectors(self):\n",
        "    alphas = np.array(self.soln[\"x\"])\n",
        "    alphas = np.array( [ alpha[0] for alpha in alphas] )\n",
        "    # print(alphas)\n",
        "    alphas = [[alphas[i],  int(i) ] for i in range(alphas.shape[0])]\n",
        "    alphas = np.array(alphas)\n",
        "    self.og_alphas = alphas\n",
        "    sorted_indices = np.argsort(self.og_alphas[:, 1])\n",
        "    self.og_alphas = self.og_alphas[sorted_indices]\n",
        "    shape = alphas.shape\n",
        "    m = shape[0]\n",
        "\n",
        "    self.init_size = alphas.shape[0]\n",
        "    support_vectors = np.array([ (alpha[0], alpha[1]) for alpha in alphas if (alpha[0] > 1e-05)] )\n",
        "    sorted_indices = np.argsort(support_vectors[:, 0])\n",
        "    self.support_vectors = support_vectors[sorted_indices]\n",
        "    self.no_of_support_vectors = support_vectors.shape[0]\n",
        "    print(self.init_size, self.no_of_support_vectors)\n",
        "    return (self.og_alphas, self.support_vectors)\n",
        "\n",
        "  def inner_product(self, x): # takes inner product of a input attribute' feature vector with weight vector\n",
        "    # temp = np.array([self.kernel(self.X[i], x) for i in range(self.m)]) \n",
        "    temp = self.X @ x \n",
        "    return np.sum(self.og_alphas[:,0] * self.Y * temp)\n",
        "  \n",
        "  def w_norm(self): # applicable for all kernels\n",
        "    temp = self.og_alphas[:, 0] \n",
        "    return math.sqrt(temp.T @ self.P @ temp) \n",
        "  \n",
        "  def get_weight(self): # only valid for linear kernel, not gaussian kernel\n",
        "    weight = np.zeros( (self.Y.shape[0], ) )\n",
        "    temp = self.Y * (self.og_alphas[:,0])\n",
        "    self.weight = ( (self.X).T @ temp)\n",
        "    # weight = np.sum ( temp2,axis = 0)\n",
        "    print(weight.shape)\n",
        "    return self.weight\n",
        "\n",
        "  def get_bias(self):\n",
        "      # m = (self.og_alphas).shape[0]\n",
        "      all_bias = []\n",
        "      for i in range(self.m):\n",
        "        alpha = self.og_alphas[i,0]\n",
        "        if (alpha < 1e-05 or (self.C - alpha) < 1e-05): continue\n",
        "        # temp = ((self.weight.T) @ self.X[i])\n",
        "        temp = self.inner_product(self.X[i])\n",
        "        bias = self.Y[i] - temp\n",
        "        all_bias.append(bias)\n",
        "      all_bias = np.array(all_bias)\n",
        "      self.bias = np.sum(all_bias)/all_bias.shape[0]\n",
        "      return self.bias\n",
        "\n",
        "  def predict(self, example):\n",
        "    temp = self.inner_product(example) + self.bias\n",
        "    temp /= self.w_norm() \n",
        "    # print(temp)\n",
        "    if (temp > 0) : predict = 1\n",
        "    else: predict = -1\n",
        "    return (predict, temp)\n",
        "\n",
        "  def get_confusion_matrix(self, test_eg, test_ans) :\n",
        "    size = test_eg.shape[0]\n",
        "    confusion_matrix = np.zeros( (self.no_of_classes, self.no_of_classes))\n",
        "    correct , incorrect = 0,0\n",
        "    for k in range(size):\n",
        "      (prediction, score) = self.predict(test_eg[k])\n",
        "      if (test_ans[k] == prediction) : correct += 1\n",
        "      else : incorrect +=  1\n",
        "      if (prediction == -1) : prediction = 0\n",
        "      copy = 1\n",
        "      if (test_ans[k] == -1) : copy = 0\n",
        "      confusion_matrix[copy][prediction] += 1\n",
        "\n",
        "\n",
        "    return (confusion_matrix, (correct / (correct + incorrect)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSif2H48QGb3"
      },
      "outputs": [],
      "source": [
        "linear_kernel = SVM(X, Y , 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wITDtXpyYwwy"
      },
      "outputs": [],
      "source": [
        "soln = linear_kernel.solve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8d3iu-Tfdiv"
      },
      "outputs": [],
      "source": [
        "\n",
        "og_alphas, support_vectors = linear_kernel.get_support_vectors()\n",
        "print(support_vectors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjAjtVjHFJOx",
        "outputId": "1d04369c-5df4-4272-9673-30f5037bdd21"
      },
      "outputs": [],
      "source": [
        "# weight = get_weight(og_alphas, X, Y)\n",
        "weight = linear_kernel.get_weight()\n",
        "print(weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZGkaSrNNpjE"
      },
      "outputs": [],
      "source": [
        "# bias = get_bias(og_alphas, X, Y, weight, 1.0)\n",
        "bias = linear_kernel.get_bias()\n",
        "print(bias)\n",
        "# bias ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce837oogcHzD"
      },
      "source": [
        "Bias is 0.725"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzXTWU1Zg4cv"
      },
      "source": [
        "We get 2903 support vectors out of 4760 training examples. We take a margin of 1e0-5 for values of alpha.\n",
        "The percentage of suport vectors is 60.99 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ6QTgXnMOK4"
      },
      "outputs": [],
      "source": [
        "# validation matrix\n",
        "folder_name = \"./svm/val/3\"\n",
        "\n",
        "new_shape = (16, 16)\n",
        "\n",
        "validation_eg = []\n",
        "answers = []\n",
        "correct , incorrect = 0,0\n",
        "for filename in os.listdir(folder_name):\n",
        "      answers.append(-1)\n",
        "      file = os.path.join(folder_name, filename)\n",
        "      temp = resize(file, new_shape)\n",
        "      validation_eg.append(temp)\n",
        "\n",
        "folder_name = \"./svm/val/4\"\n",
        "for filename in os.listdir(folder_name):\n",
        "      answers.append(1)\n",
        "      file = os.path.join(folder_name, filename)\n",
        "      temp = resize(file, new_shape)\n",
        "      validation_eg.append(temp)\n",
        "\n",
        "validation_eg = np.array(validation_eg)\n",
        "answers = np.array(answers)\n",
        "\n",
        "# X = np.vstack(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp-8Ls8CUUir"
      },
      "outputs": [],
      "source": [
        "( confusion_matrix, accuracy) = linear_kernel.get_confusion_matrix(validation_eg, answers)\n",
        "print(f\"accuracy is {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEen9AHzb_Yx"
      },
      "source": [
        "We get validation accuracy as 72.75 %"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6jc-pbHdgoT"
      },
      "outputs": [],
      "source": [
        "class Gaussian_Kernel(SVM):\n",
        "   def __init__(self, X, Y, C, gamma):\n",
        "      self.X = X\n",
        "      self.Y = Y\n",
        "      self.C = C\n",
        "      self.m = Y.shape[0]\n",
        "      self.gamma = gamma\n",
        "      # print(\"here in gaussian\")\n",
        "      self.gaussian_kernel_matrix()\n",
        "      # print(self.kernel_matrix) \n",
        "      self.P = matrix(self.kernel_matrix)\n",
        "      self.q = matrix(np.full( (self.m, ), -1 ))\n",
        "\n",
        "      temp = np.full( (self.m, ) , 1)\n",
        "      temp2 = np.full( (self.m, ) , -1)\n",
        "      self.G = matrix(np.vstack( ( np.diag(temp2), np.diag(temp))  ) )\n",
        "\n",
        "      temp = np.full( (self.m, ), C)\n",
        "      self.h = matrix(np.hstack( ( np.zeros( (self.m, ) ), temp) ) )\n",
        "\n",
        "      self.A = matrix(np.vstack( (self.Y, )))\n",
        "      self.b = matrix(np.zeros( (1,) ))\n",
        "\n",
        "      self.P = matrix( np.array(self.P), tc='d')\n",
        "      self.q = matrix( np.array(self.q), tc='d')\n",
        "      self.G = matrix( np.array(self.G), tc='d')\n",
        "      self.h = matrix( np.array(self.h), tc='d')\n",
        "      self.A = matrix( np.array(self.A), tc='d')\n",
        "      self.b = matrix( np.array(self.b), tc='d')\n",
        "\n",
        "      self.soln = None\n",
        "      self.no_of_classes = 2\n",
        "\n",
        "\n",
        "   def kernel(self, x, y): # not used, only for consistency for using get_P()\n",
        "    #  temp = x - y\n",
        "     norm_sq = (x - y).T @ (x - y)\n",
        "     return math.exp(-self.gamma * norm_sq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-JKRc6NhiOt"
      },
      "outputs": [],
      "source": [
        "C = 1.0\n",
        "gamma = 0.001\n",
        "gaussian_kernel = Gaussian_Kernel(X, Y, C, gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otrg0FXKiZjS"
      },
      "outputs": [],
      "source": [
        "soln2 = gaussian_kernel.solve()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxarqFN3_VSo"
      },
      "outputs": [],
      "source": [
        "gaussian_kernel.get_support_vectors()\n",
        "gaussian_kernel.get_bias()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYbszgJSfAqW"
      },
      "outputs": [],
      "source": [
        "(confusion_matrix, accuracy) = gaussian_kernel.get_confusion_matrix(validation_eg, answers)\n",
        "print(f\"accuracy is {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd7Fa9JNf7fI"
      },
      "outputs": [],
      "source": [
        "# plotting images\n",
        "def plot(svm, svm_name, flag = True ):\n",
        "  top_6 = svm.support_vectors[-6:]\n",
        "\n",
        "  # print(top_6)\n",
        "  top_6 = np.array([ (svm.X[ int(sv[1]) ]) * 255.0 for sv in top_6])\n",
        "  top_6 = np.array([ img.reshape((16,16,3)) for img in top_6])\n",
        "  cnt = 0\n",
        "  for img in top_6:\n",
        "\n",
        "    cnt += 1\n",
        "    cv2.imwrite(f\"img_{cnt}_{svm_name}.png\", img)\n",
        "\n",
        "  if (flag):\n",
        "    resized_weight = weight * 255.0\n",
        "    resized_weight = resized_weight.reshape( (16, 16, 3) )\n",
        "    cv2.imwrite(f\"weight_{svm_name}.png\", resized_weight)\n",
        "\n",
        "def get_common_support_vectors(svm1, svm2):\n",
        "    v1 = set( svm1.support_vectors[:, 1] )\n",
        "    v2 = set( svm2.support_vectors[:, 1]   )\n",
        "    print(f\"lens are {len(v1)} and {len(v2)}\")\n",
        "    common = v1 & v2 # intersection of two sets\n",
        "    return len(common)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P82wFCCOnbo_"
      },
      "outputs": [],
      "source": [
        "plot(linear_kernel, \"Linear\")\n",
        "plot(gaussian_kernel, \"Gaussian\", False)\n",
        "print(get_common_support_vectors(linear_kernel, gaussian_kernel))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrU0QDIrx0C9"
      },
      "source": [
        "Linear kernel had 2903 (60.99 %) support vectors, and Gaussian has 3453 (72.54 %) support vectors. The common support vectors are 2698 (56.68 %) in count."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SISNFZvzanC"
      },
      "source": [
        "Validation accuracy for Gaussian is 77.75 % (compared to 72.75 % for linear kernel, an increase of 5 %) ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhqHAqnfFF-G"
      },
      "outputs": [],
      "source": [
        "# !pip install scikit\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQYSLe4FLv_R"
      },
      "outputs": [],
      "source": [
        "sk_linear_kernel = svm.SVC(C = 1.0, kernel = \"linear\")\n",
        "sk_linear_kernel.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sk_gaussian_kernel = svm.SVC(C = 1.0, kernel = \"rbf\", gamma = 0.001)\n",
        "sk_gaussian_kernel.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRCK9NTWM0R7"
      },
      "outputs": [],
      "source": [
        "predictions = sk_linear_kernel.predict(validation_eg)\n",
        "correct , incorrect = 0,0\n",
        "\n",
        "for i in range(predictions.shape[0]):\n",
        "  if (predictions[i] == answers[i]): correct += 1\n",
        "  else : incorrect += 1\n",
        "\n",
        "print(f\"Correct : {correct}\")\n",
        "print(f\"Incorrect : {incorrect}\")\n",
        "print(f\"accuracy : {correct / (correct + incorrect)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S4Efa5iO0V3"
      },
      "outputs": [],
      "source": [
        "predictions = sk_gaussian_kernel.predict(validation_eg)\n",
        "correct , incorrect = 0,0\n",
        "\n",
        "for i in range(predictions.shape[0]):\n",
        "  if (predictions[i] == answers[i]): correct += 1\n",
        "  else : incorrect += 1\n",
        "\n",
        "print(f\"Correct : {correct}\")\n",
        "print(f\"Incorrect : {incorrect}\")\n",
        "print(f\"accuracy : {correct / (correct + incorrect)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_qpk6zrPTri"
      },
      "source": [
        "As can be observed, the accuracy obtained from the scikit learn SVM function is exactly the same as obtained from our implementation. Hence our model has been implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN9bMpruPi9C"
      },
      "outputs": [],
      "source": [
        "linear_sv = sk_linear_kernel.support_\n",
        "gaussian_sv = sk_gaussian_kernel.support_\n",
        "# print(linear_sv)\n",
        "sk_set1 = set(linear_sv)\n",
        "sk_set2 = set(gaussian_sv)\n",
        "set1 = set( linear_kernel.support_vectors[:, 1] )\n",
        "set2 = set( gaussian_kernel.support_vectors[:, 1]   )\n",
        "\n",
        "print(f\"no of support vectors for sklearn linear svm is {len(sk_set1)}\")\n",
        "print(f\"no of support vectors for sklearn gaussian svm is {len(sk_set2)}\")\n",
        "print(f\"no of support vectors for  linear svm is {len(set1)}\")\n",
        "print(f\"no of support vectors for  gaussian svm is {len(set2)}\")\n",
        "\n",
        "print(f\"no of support vectors common for linear svm are {len(sk_set1 & set1)}\")\n",
        "print(f\"no of support vectors common for gaussian svm is {len(sk_set2 & set2)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcU5MvRXRacG"
      },
      "source": [
        "no of support vectors for sklearn linear svm is 2899\n",
        "\n",
        "no of support vectors for sklearn gaussian svm is 3398\n",
        "\n",
        "no of support vectors for  linear svm is 2903\n",
        "\n",
        "no of support vectors for  gaussian svm is 3453\n",
        "\n",
        "no of support vectors common for linear svm are 2899\n",
        "\n",
        "no of support vectors common for gaussian svm is 3398\n",
        "\n",
        "From the numbers we conclude that the sv used in both of our implmented models are also used by the corresponding sklearn models, along with a few additional sv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWTXi--ARmwn"
      },
      "outputs": [],
      "source": [
        "sk_weight = sk_linear_kernel.coef_\n",
        "sk_bias = sk_linear_kernel.intercept_\n",
        "\n",
        "og_weight = linear_kernel.get_weight()\n",
        "og_bias = linear_kernel.get_bias()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVHXGdanSpnt"
      },
      "outputs": [],
      "source": [
        "print(f\"bias obtained for sklearn linear svm is {sk_bias}\")\n",
        "\n",
        "print(f\"bias obtained for  linear svm is {og_bias}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28yY1rGrTr0v"
      },
      "outputs": [],
      "source": [
        "temp = (sk_weight[0] - og_weight )\n",
        "norm_sk = sk_weight[0].T @ sk_weight[0]\n",
        "norm = temp.T @ temp\n",
        "print(math.sqrt(norm/norm_sk) * 100 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35_6SaTJTcsi"
      },
      "source": [
        "bias obtained for sklearn linear svm is 0.7251\n",
        "bias obtained for  linear svm is 0.7251\n",
        "\n",
        "The biases obtained are identical, the weight vectors are also almost identical, the rms error being 0.247 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VKQw85IVAIS"
      },
      "source": [
        "time taken by our linear svm is 80 sec.\n",
        "\n",
        "time taken by our gaussian svm is 62 sec.\n",
        "\n",
        "time taken by sklearn linear svm is 12 sec\n",
        "\n",
        "time taken by sklearn gaussian svm is 7 sec\n",
        "\n",
        "Hence there is quite a reduction in the training time when using sklearn !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multiclass Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb5XGRZWe3bw"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Multi_Class_SVM:\n",
        "  def __init__(self, X, Y, k, C, gamma):\n",
        "    self.m = X.shape[0]\n",
        "    # print(self.m)\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.no_of_classes = k\n",
        "    self.training_datasets = self.split_dataset()\n",
        "    self.C = C\n",
        "    self.gamma = gamma\n",
        "    self.misclassifications = [[[] for i in range(self.no_of_classes)] for j in range(self.no_of_classes)] \n",
        "\n",
        "\n",
        "  def split_dataset(self):\n",
        "    temp = [[] for i in range(self.no_of_classes)]\n",
        "    for i in range(self.m):\n",
        "      (temp[self.Y[i]]).append(self.X[i])\n",
        "\n",
        "    return np.array(temp)\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "    self.model = np.full((self.no_of_classes, self.no_of_classes), None, dtype=object)\n",
        "    for i in range(self.no_of_classes):\n",
        "      for j in range(self.no_of_classes):\n",
        "        if (i == j or self.model[i,j] != None): continue\n",
        "        print(f\"training being done for classes {i} and {j}\")\n",
        "        X_ij = np.vstack( ( np.array(self.training_datasets[i]), np.array(self.training_datasets[j]) )  )\n",
        "        size1 = len(self.training_datasets[i])\n",
        "        size2 = len(self.training_datasets[j])\n",
        "        Y_ij = np.zeros( size1 + size2 )\n",
        "        for k in range(size1 ):\n",
        "          Y_ij[k] = -1\n",
        "        for k in range(size1, size1 + size2):\n",
        "          Y_ij[k] = 1\n",
        "        # print(X_ij.shape, Y_ij.shape)\n",
        "        self.model[i,j] = Gaussian_Kernel(X_ij, Y_ij, self.C, self.gamma)\n",
        "        print(\"invoking solver now\") \n",
        "        (self.model[i,j]).solve()\n",
        "        print(\"solved\")\n",
        "        (self.model[i,j]).get_support_vectors()\n",
        "        (self.model[i,j]).get_bias()\n",
        "        self.model[j, i] = self.model[i,j]\n",
        "    print(\"training complete\")\n",
        "\n",
        "  def predict(self, eg):\n",
        "    scores = np.zeros( (self.no_of_classes, ))\n",
        "    counts =  np.zeros( (self.no_of_classes, ))\n",
        "    done = np.zeros((self.no_of_classes, self.no_of_classes))\n",
        "    for i in range(self.no_of_classes):\n",
        "      for j in range(self.no_of_classes):\n",
        "        if (i == j or done[i][j] == 1) : continue\n",
        "        done[i][j] = 1\n",
        "        done[j][i] = 1\n",
        "        # i is -1, j is one\n",
        "        (prediction, score) = self.model[i,j].predict(eg)\n",
        "        if (prediction == -1) : prediction = i\n",
        "        else : prediction = j\n",
        "        counts[prediction] += 1\n",
        "        if (score > 0) : scores[prediction] += score\n",
        "        else: scores[prediction] -= score\n",
        "\n",
        "    max_count = np.max(counts)\n",
        "    max_indices = np.where(counts == max_count)[0]\n",
        "    max_scores = np.array([ (scores[i], i) for i in max_indices])\n",
        "    sorted_indices = np.argsort(max_scores[:, 1])\n",
        "    max_scores = max_scores[sorted_indices]\n",
        "    return (max_scores[-1, 1], max_scores[-1, 0])\n",
        "\n",
        "  def get_confusion_matrix(self, test_eg, test_ans) :\n",
        "    size = test_eg.shape[0]\n",
        "    confusion_matrix = np.zeros( (self.no_of_classes, self.no_of_classes), dtype=int)\n",
        "    correct , incorrect = 0,0\n",
        "    for k in range(size):\n",
        "        (prediction, score) = self.predict(test_eg[k])\n",
        "        # print(prediction, \"\\n\", test_ans[k]) \n",
        "        # print(\"prediction is \", prediction) \n",
        "        self.misclassifications[test_ans[k]][int(prediction)].append(test_eg[k])  \n",
        "        confusion_matrix[test_ans[k]][int(prediction)] += 1 \n",
        "        if (test_ans[k] == prediction) : correct += 1\n",
        "        else : incorrect +=  1\n",
        "\n",
        "    return (confusion_matrix, (correct / (correct + incorrect)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# design matrix\n",
        "folder_name = \"./svm/train/\"\n",
        "no_of_classes = 6\n",
        "classes = [i for i in range(no_of_classes)]\n",
        "X_full = tuple()\n",
        "new_shape = (16, 16)\n",
        "Y_full = np.array([], dtype = int)\n",
        "for label in classes:\n",
        "  for filename in os.listdir(f\"{folder_name}{label}\"):\n",
        "        file = os.path.join(f\"{folder_name}{label}\", filename)\n",
        "        Z = resize(file, new_shape)\n",
        "        X_full = X_full + ( Z[None , ...], )\n",
        "        Y_full = np.append(Y_full, label)\n",
        "\n",
        "X_full = np.vstack(X_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# design matrix\n",
        "folder_name = \"./svm/val/\"\n",
        "no_of_classes = 6\n",
        "classes = [i for i in range(no_of_classes)]\n",
        "X_val_full = tuple()\n",
        "new_shape = (16, 16)\n",
        "Y_val_full = np.array([], dtype = int)\n",
        "for label in classes:\n",
        "  for filename in os.listdir(f\"{folder_name}{label}\"):\n",
        "        file = os.path.join(f\"{folder_name}{label}\", filename)\n",
        "        Z = resize(file, new_shape)\n",
        "        X_val_full = X_val_full + ( Z[None , ...], )\n",
        "        Y_val_full = np.append(Y_val_full, label)\n",
        "\n",
        "X_val_full = np.vstack(X_val_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvrWq1T-tELZ"
      },
      "outputs": [],
      "source": [
        "C = 1.0\n",
        "gamma = 0.001\n",
        "multiclass_classifier = Multi_Class_SVM(X_full, Y_full, no_of_classes, C, gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "multiclass_classifier.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "aBMvRTZC1SvP",
        "outputId": "194afcb6-e396-4124-8e0d-d26ed999a2ee"
      },
      "outputs": [],
      "source": [
        "\n",
        "sk_multiclass_classifier = svm.SVC(C = C, gamma = gamma, kernel = \"rbf\") \n",
        "# , decision_function_shape = \"ovr\",break_ties = True)\n",
        "sk_multiclass_classifier.fit(X_full, Y_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def draw_confusion_matrix( confusion_matrix, name):\n",
        "    \n",
        "        correct = 0 \n",
        "        total = 0 \n",
        "        fig, ax = plt.subplots(figsize=(10,10))\n",
        "        ax.matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.3) \n",
        "        max_diag = 0 \n",
        "        max_diag_label = 0\n",
        "        for i in range(confusion_matrix.shape[0]):\n",
        "            for j in range(confusion_matrix.shape[1]):\n",
        "                total += confusion_matrix[i,j]\n",
        "                if (i == j) : \n",
        "                    correct += confusion_matrix[i,j]\n",
        "                    if (max_diag < confusion_matrix[i,j]):\n",
        "                        max_diag = confusion_matrix[i,j]\n",
        "                        max_diag_label = i\n",
        "    \n",
        "                ax.text(x=j, y=i,s= confusion_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "        \n",
        "        plt.xlabel('Predictions', fontsize=18)\n",
        "        plt.ylabel('Actuals', fontsize=18)\n",
        "        plt.title('Confusion Matrix', fontsize=18)\n",
        "        plt.savefig(f\"confusion_matrix_{name}.png\")\n",
        "        # plt.show()\n",
        "        print(f\"accuracy is {correct/total}\")\n",
        "        print(f\"label with max diagonal is {max_diag_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "(confusion_matrix, accuracy) = multiclass_classifier.get_confusion_matrix( X_val_full, Y_val_full)\n",
        "print(f\"accuracy is {accuracy}\")\n",
        "draw_confusion_matrix(confusion_matrix, \"our_multiclass\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualising error images \n",
        "cnt = 0 \n",
        "for img in multiclass_classifier.misclassifications[4][2]:\n",
        "    if (cnt > 2): break\n",
        "    cnt += 1 \n",
        "    img = img * 255.0\n",
        "    img = img.reshape((16,16,3))\n",
        "    cv2.imwrite(f\"img_4_2_{cnt}.png\", img)\n",
        "cnt = 0 \n",
        "for img in multiclass_classifier.misclassifications[4][3]:\n",
        "    if (cnt > 2): break\n",
        "    cnt += 1 \n",
        "    img = img * 255.0\n",
        "    img = img.reshape((16,16,3))\n",
        "    cv2.imwrite(f\"img_4_3_{cnt}.png\", img)\n",
        "cnt = 0 \n",
        "for img in multiclass_classifier.misclassifications[0][3]:\n",
        "    if (cnt > 2): break\n",
        "    cnt += 1 \n",
        "    img = img * 255.0\n",
        "    img = img.reshape((16,16,3))\n",
        "    cv2.imwrite(f\"img_0_3_{cnt}.png\", img)\n",
        "cnt = 0 \n",
        "for img in multiclass_classifier.misclassifications[1][5]:\n",
        "    if (cnt > 2): break\n",
        "    cnt += 1 \n",
        "    img = img * 255.0\n",
        "    img = img.reshape((16,16,3))\n",
        "    cv2.imwrite(f\"img_1_5_{cnt}.png\", img)\n",
        "\n",
        "\n",
        "# resized_weight = weight * 255.0\n",
        "# resized_weight = resized_weight.reshape( (16, 16, 3))\n",
        "# cv2.imwrite(f\"weight_{svm_name}.png\", resized_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "set 0 has images of houses and buildings, 1 has of forests and greenery, 2 has of ice and glaciers, 3 has of cloudy sky and mountains, 4 has of coasts and oceans,  5 of cities. \n",
        "\n",
        "Of these the most frequent pair of misclassified classes are (first is actual, second is prediction) : \n",
        "(4,2), (4,3), (0,3), (1,5). \n",
        "Based on the above observations, it is easy to make sense of the visualisations of the misclassified examples as showm. For eg - images of 4 and 2 both are predominantly white and blue, thus they are misclassified as each other the most. \n",
        "Similiar logic holds for 4 and 3, and so on. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESrsyH3_7PuW",
        "outputId": "e79dc587-5e11-471a-b37f-cd97fcae4771"
      },
      "outputs": [],
      "source": [
        "predictions = sk_multiclass_classifier.predict(X_val_full)\n",
        "correct , incorrect = 0,0\n",
        "\n",
        "# print(predictions.shape[0])\n",
        "sk_confusion_matrix = np.array( [[0 for i in range(no_of_classes)] for j in range(no_of_classes)] ) \n",
        "\n",
        "for i in range(predictions.shape[0]):\n",
        "  # print(predictions[i], Y_val_full[i])\n",
        "  sk_confusion_matrix[Y_val_full[i]][predictions[i]] += 1\n",
        "  if (predictions[i] == Y_val_full[i]): correct += 1\n",
        "  else : incorrect += 1\n",
        "\n",
        "print(f\"Correct : {correct}\")\n",
        "print(f\"Incorrect : {incorrect}\")\n",
        "print(f\"accuracy : {correct / (correct + incorrect)}\")\n",
        "draw_confusion_matrix(sk_confusion_matrix, \"sklearn_multiclass\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each class has 200 samples in the validation set. The confusion matrices obtained from our implementation and from sklearn are largely similiar, differing by only a small amt. \n",
        "We also observe that class 1 is classified most correctly, whereas class 4 is the least correctly classifed class. \n",
        "The largest off diagonal entry is (4,2), which means that most misclassifications have been done for class 4 where it was confused for class 2 (58 examples). Similarly we observe that class 0 is misclassified most frequently as class 5, 1 as 5, 3 as 2, 4 as 2, 5 as 0. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k = 5 \n",
        "def get_splits(x,y,k):\n",
        "    m = x.shape[0]\n",
        "    splits = []\n",
        "    for i in range(k):\n",
        "        splits.append( (x[int(i*m/k) : int((i+1)*m/k)], y[int(i*m/k) : int((i+1)*m/k)]) )\n",
        "    \n",
        "    val_splits = [] \n",
        "    for i in range(k):\n",
        "        val_split = [] \n",
        "        for j in range(k):\n",
        "            if (i == j): continue\n",
        "            val_split.append(splits[j]) \n",
        "        x_tup = [] \n",
        "        y_tup = []\n",
        "        for s in val_split:\n",
        "            x_tup.append(s[0])\n",
        "            y_tup.append(s[1]) \n",
        "        x_tup = np.vstack(tuple(x_tup)) \n",
        "        y_tup = np.hstack(tuple(y_tup))\n",
        "        val_splits.append((x_tup, y_tup)) \n",
        "    return (val_splits, (splits)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perm = np.random.permutation([i for i in range(X_full.shape[0])]) \n",
        "combined_x = np.zeros(X_full.shape)\n",
        "combined_y = np.zeros(Y_full.shape)\n",
        "for i in range(X_full.shape[0]):\n",
        "    combined_x[i] = X_full[perm[i]]\n",
        "    combined_y[i] = Y_full[perm[i]] \n",
        "\n",
        "(splits, og_splits) = get_splits(combined_x, combined_y, k)\n",
        "for split in splits:\n",
        "    print(split[0].shape, split[1].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "C_arr = np.array([1e-05, 1e-03, 1, 5, 10]) \n",
        "cross_validation_ac = np.zeros(C_arr.shape)\n",
        "validation_ac = np.zeros(C_arr.shape)\n",
        "k = 5 \n",
        "for j in range( C_arr.shape[0]):\n",
        "    avg = 0 \n",
        "    for i in range(k):\n",
        "        correct = 0\n",
        "        incorrect = 0 \n",
        "        sk_model = svm.SVC(C = C_arr[j] , kernel = \"rbf\", gamma = 0.001) \n",
        "        sk_model.fit(splits[i][0], splits[i][1]) \n",
        "        predictions = sk_model.predict(og_splits[i][0]) \n",
        "\n",
        "        for w in range(og_splits[i][1].shape[0]):\n",
        "            if (predictions[w] == og_splits[i][1][w]): correct += 1\n",
        "            else : incorrect += 1\n",
        "        print(f\"for model {j} and dataset {i}, correct : {correct} and incorrect : {incorrect}\") \n",
        "        accuracy = correct / (correct + incorrect) \n",
        "        avg += accuracy\n",
        "    avg /= k \n",
        "    cross_validation_ac[j] = avg \n",
        "    sk_full_model = svm.SVC(C = C_arr[j] , kernel = \"rbf\", gamma = 0.001) \n",
        "    sk_full_model.fit(combined_x,  combined_y) \n",
        "    predictions = sk_full_model.predict(X_val_full) \n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    for w in range(Y_val_full.shape[0]):\n",
        "        if (predictions[w] == Y_val_full[w]): correct += 1\n",
        "        else : incorrect += 1\n",
        "    print(f\"for model {j} validation, correct : {correct} and incorrect : {incorrect}\") \n",
        "    accuracy = correct / (correct + incorrect)\n",
        "    validation_ac[j] = accuracy\n",
        "print(cross_validation_ac)\n",
        "print(validation_ac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for j in range( C_arr.shape[0]):\n",
        "    correct = 0\n",
        "    incorrect = 0 \n",
        "    sk_model = svm.SVC(C = C_arr[j] , kernel = \"rbf\", gamma = 0.001) \n",
        "    sk_model.fit(X_full, Y_full) \n",
        "    predictions = sk_model.predict(X_val_full)\n",
        "    for w in range(Y_val_full.shape[0]):\n",
        "        if (predictions[w] == Y_val_full[w]): correct += 1\n",
        "        else : incorrect += 1\n",
        "    print(f\"for model {j} on full dataset, correct : {correct} and incorrect : {incorrect}\") \n",
        "    accuracy = correct / (correct + incorrect) \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_line(x, y, xlabel, ylabel, title):\n",
        "    plt.plot(x, y, marker='o', label = title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    # plt.title(title)\n",
        "    # plt.savefig(f\"{name}.png\")\n",
        "    # plt.show()\n",
        "\n",
        "plot_line( np.log(C_arr), cross_validation_ac, \"log C\", \"accuracy\", \"cross_validation_accuracy\")\n",
        "plot_line( np.log(C_arr), validation_ac, \"log C\", \"accuracy\", \"validation_accuracy\") \n",
        "plt.title(\"cross_validation_accuracy vs validation_accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"cross_validation_accuracy vs validation_accuracy.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We observe that the value of C which gives the best cross validation accuracy is also the same which gives the\n",
        "best validation accuracy. \n",
        "In fact as the cross validation accuracy (CVA) increases, the validation accuracy (VA) also increases with C. \n",
        "\n",
        "Thus cross validation accuracy serves as a good measure of the generalized accuracy, i.e we can say for our case that if a model with C = C1 has better cross validation accuracy than model with C = C2, then its generalized accuracy is also expected to be better."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
